{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(a)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"mnist_train.csv\")\n",
    "test_data = pd.read_csv(\"mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data Shape: (60000, 785)\n",
      "Test data Shape: (10000, 785)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data Shape:\",train_data.shape)\n",
    "print(\"Test data Shape:\",test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      7    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      2    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label    0\n",
       "1x1      0\n",
       "1x2      0\n",
       "1x3      0\n",
       "1x4      0\n",
       "        ..\n",
       "28x24    0\n",
       "28x25    0\n",
       "28x26    0\n",
       "28x27    0\n",
       "28x28    0\n",
       "Length: 785, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label    0\n",
       "1x1      0\n",
       "1x2      0\n",
       "1x3      0\n",
       "1x4      0\n",
       "        ..\n",
       "28x24    0\n",
       "28x25    0\n",
       "28x26    0\n",
       "28x27    0\n",
       "28x28    0\n",
       "Length: 785, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data['label'] \n",
    "x = train_data.drop(columns = 'label')\n",
    "x = x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2 ,random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear = SVC(kernel='linear')\n",
    "model_linear.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 0, 6, 6, 9, 1, 1, 5, 6, 2, 0, 1, 4, 7, 6, 2, 5, 5, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_linear.predict(X_test)\n",
    "y_pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1095,    0,    5,    2,    3,   13,    4,    1,    4,    0],\n",
       "       [   0, 1328,    6,    3,    0,    0,    0,    2,    5,    1],\n",
       "       [   8,   12, 1161,   15,    8,    5,   12,   11,    8,    1],\n",
       "       [   6,    5,   30, 1077,    1,   37,    2,    3,   16,    5],\n",
       "       [   2,    5,   12,    0, 1132,    0,    4,    6,    2,   37],\n",
       "       [  12,    7,    9,   39,    8,  993,    9,    2,   20,    5],\n",
       "       [  12,    4,   12,    0,    6,   20, 1146,    0,    1,    0],\n",
       "       [   4,    5,   17,    4,   17,    4,    0, 1243,    4,   38],\n",
       "       [   8,   21,   20,   27,    4,   24,   10,    5, 1032,    3],\n",
       "       [   4,    4,    5,    9,   37,    7,    0,   22,   14, 1008]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_Matrix = confusion_matrix(y_test, y_pred)\n",
    "C_Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1-Score from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_scratch(ground_truth, prediction, average = True):\n",
    "    if average == True:\n",
    "        TP = C_Matrix.diagonal()\n",
    "        FP = C_Matrix.sum(axis=1)-TP\n",
    "        FN = C_Matrix.sum(axis=0)-TP\n",
    "        TN = C_Matrix.sum().sum()-TP-FP-FN\n",
    "        Precision = TP/(TP+FP)\n",
    "        Recall = TP/(TP+FN)\n",
    "        f1score = 2 * Precision * Recall / (Precision + Recall)\n",
    "        f1 = f1score.mean()\n",
    "        return f1\n",
    "    else:\n",
    "        TP = C_Matrix.diagonal()\n",
    "        FP = C_Matrix.sum(axis=1)-TP\n",
    "        FN = C_Matrix.sum(axis=0)-TP\n",
    "        TN = C_Matrix.sum().sum()-TP-FP-FN\n",
    "        Precision = TP/(TP+FP)\n",
    "        Recall = TP/(TP+FN)\n",
    "        f1score = 2 * Precision * Recall / (Precision + Recall)\n",
    "        return f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96136962, 0.97076023, 0.92216044, 0.91348601, 0.93708609,\n",
       "       0.89986407, 0.95979899, 0.94488788, 0.91327434, 0.91304348])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scratch(y_test, y_pred, average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9335731152719008"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scratch(y_test, y_pred, average=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1-Score from Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9335731152719008"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average ='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96136962, 0.97076023, 0.92216044, 0.91348601, 0.93708609,\n",
       "       0.89986407, 0.95979899, 0.94488788, 0.91327434, 0.91304348])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average =None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9345833333333333"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(b)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_linear_model = SVC(kernel='rbf')\n",
    "non_linear_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rbf = non_linear_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97825"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='poly')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_model = SVC(kernel='poly')\n",
    "poly_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_poly = poly_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9768333333333333"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(c)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=10, shuffle=True),\n",
       "             estimator=SVC(),\n",
       "             param_grid=[{&#x27;C&#x27;: [5, 10], &#x27;gamma&#x27;: [0.01, 0.001, 0.0001]}],\n",
       "             return_train_score=True, scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=10, shuffle=True),\n",
       "             estimator=SVC(),\n",
       "             param_grid=[{&#x27;C&#x27;: [5, 10], &#x27;gamma&#x27;: [0.01, 0.001, 0.0001]}],\n",
       "             return_train_score=True, scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=10, shuffle=True),\n",
       "             estimator=SVC(),\n",
       "             param_grid=[{'C': [5, 10], 'gamma': [0.01, 0.001, 0.0001]}],\n",
       "             return_train_score=True, scoring='accuracy')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 10)\n",
    "model = SVC(kernel=\"rbf\")\n",
    "Grid_Search = GridSearchCV(estimator = model,param_grid = [ {'gamma': [1e-2, 1e-3, 1e-4],'C': [5,10]}],scoring= 'accuracy',cv = folds,return_train_score=True)      \n",
    "Grid_Search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82.022877</td>\n",
       "      <td>1.620856</td>\n",
       "      <td>55.674841</td>\n",
       "      <td>4.625250</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 5, 'gamma': 0.01}</td>\n",
       "      <td>0.979479</td>\n",
       "      <td>0.977604</td>\n",
       "      <td>0.981563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979521</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997969</td>\n",
       "      <td>0.998073</td>\n",
       "      <td>0.997839</td>\n",
       "      <td>0.997865</td>\n",
       "      <td>0.997943</td>\n",
       "      <td>0.997938</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99.724374</td>\n",
       "      <td>3.441869</td>\n",
       "      <td>65.657000</td>\n",
       "      <td>3.952859</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 5, 'gamma': 0.001}</td>\n",
       "      <td>0.946042</td>\n",
       "      <td>0.946458</td>\n",
       "      <td>0.947292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945646</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>4</td>\n",
       "      <td>0.954010</td>\n",
       "      <td>0.954427</td>\n",
       "      <td>0.953620</td>\n",
       "      <td>0.954740</td>\n",
       "      <td>0.953438</td>\n",
       "      <td>0.954047</td>\n",
       "      <td>0.000486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>212.991456</td>\n",
       "      <td>2.620406</td>\n",
       "      <td>105.200622</td>\n",
       "      <td>0.778440</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 5, 'gamma': 0.0001}</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.921771</td>\n",
       "      <td>0.923438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.920208</td>\n",
       "      <td>0.002180</td>\n",
       "      <td>6</td>\n",
       "      <td>0.922708</td>\n",
       "      <td>0.922865</td>\n",
       "      <td>0.921823</td>\n",
       "      <td>0.923099</td>\n",
       "      <td>0.923385</td>\n",
       "      <td>0.922776</td>\n",
       "      <td>0.000528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73.194609</td>\n",
       "      <td>1.812835</td>\n",
       "      <td>49.453996</td>\n",
       "      <td>0.707506</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01}</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.977604</td>\n",
       "      <td>0.982708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979875</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999583</td>\n",
       "      <td>0.999479</td>\n",
       "      <td>0.999427</td>\n",
       "      <td>0.999557</td>\n",
       "      <td>0.999505</td>\n",
       "      <td>0.999510</td>\n",
       "      <td>0.000056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77.207629</td>\n",
       "      <td>0.334548</td>\n",
       "      <td>53.353911</td>\n",
       "      <td>0.286822</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001}</td>\n",
       "      <td>0.950833</td>\n",
       "      <td>0.952396</td>\n",
       "      <td>0.952396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950958</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>3</td>\n",
       "      <td>0.962995</td>\n",
       "      <td>0.962135</td>\n",
       "      <td>0.961615</td>\n",
       "      <td>0.962708</td>\n",
       "      <td>0.961641</td>\n",
       "      <td>0.962219</td>\n",
       "      <td>0.000556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>149.641071</td>\n",
       "      <td>1.984764</td>\n",
       "      <td>90.649604</td>\n",
       "      <td>2.657392</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.0001}</td>\n",
       "      <td>0.928229</td>\n",
       "      <td>0.927292</td>\n",
       "      <td>0.930104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.927479</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>5</td>\n",
       "      <td>0.930677</td>\n",
       "      <td>0.931719</td>\n",
       "      <td>0.930078</td>\n",
       "      <td>0.931536</td>\n",
       "      <td>0.930781</td>\n",
       "      <td>0.930958</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0      82.022877      1.620856        55.674841        4.625250       5   \n",
       "1      99.724374      3.441869        65.657000        3.952859       5   \n",
       "2     212.991456      2.620406       105.200622        0.778440       5   \n",
       "3      73.194609      1.812835        49.453996        0.707506      10   \n",
       "4      77.207629      0.334548        53.353911        0.286822      10   \n",
       "5     149.641071      1.984764        90.649604        2.657392      10   \n",
       "\n",
       "  param_gamma                      params  split0_test_score  \\\n",
       "0        0.01     {'C': 5, 'gamma': 0.01}           0.979479   \n",
       "1       0.001    {'C': 5, 'gamma': 0.001}           0.946042   \n",
       "2      0.0001   {'C': 5, 'gamma': 0.0001}           0.920000   \n",
       "3        0.01    {'C': 10, 'gamma': 0.01}           0.980000   \n",
       "4       0.001   {'C': 10, 'gamma': 0.001}           0.950833   \n",
       "5      0.0001  {'C': 10, 'gamma': 0.0001}           0.928229   \n",
       "\n",
       "   split1_test_score  split2_test_score  ...  mean_test_score  std_test_score  \\\n",
       "0           0.977604           0.981563  ...         0.979521        0.001314   \n",
       "1           0.946458           0.947292  ...         0.945646        0.001414   \n",
       "2           0.921771           0.923438  ...         0.920208        0.002180   \n",
       "3           0.977604           0.982708  ...         0.979875        0.001655   \n",
       "4           0.952396           0.952396  ...         0.950958        0.001523   \n",
       "5           0.927292           0.930104  ...         0.927479        0.001594   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                2            0.997969            0.998073   \n",
       "1                4            0.954010            0.954427   \n",
       "2                6            0.922708            0.922865   \n",
       "3                1            0.999583            0.999479   \n",
       "4                3            0.962995            0.962135   \n",
       "5                5            0.930677            0.931719   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.997839            0.997865            0.997943   \n",
       "1            0.953620            0.954740            0.953438   \n",
       "2            0.921823            0.923099            0.923385   \n",
       "3            0.999427            0.999557            0.999505   \n",
       "4            0.961615            0.962708            0.961641   \n",
       "5            0.930078            0.931536            0.930781   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.997938         0.000083  \n",
       "1          0.954047         0.000486  \n",
       "2          0.922776         0.000528  \n",
       "3          0.999510         0.000056  \n",
       "4          0.962219         0.000556  \n",
       "5          0.930958         0.000600  \n",
       "\n",
       "[6 rows x 22 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(Grid_Search.cv_results_)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(d)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10, gamma=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10, gamma=0.01)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10, gamma=0.01)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = SVC(C= 10,kernel='rbf', gamma= 0.01)\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_best = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9824166666666667"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1119,    0,    1,    0,    0,    0,    2,    1,    2,    2],\n",
       "       [   0, 1338,    5,    0,    0,    0,    0,    2,    0,    0],\n",
       "       [   1,    1, 1225,    3,    2,    1,    0,    7,    1,    0],\n",
       "       [   2,    0,   12, 1148,    0,   10,    0,    3,    6,    1],\n",
       "       [   0,    3,    2,    0, 1180,    0,    0,    2,    1,   12],\n",
       "       [   3,    1,    2,    6,    1, 1076,    5,    1,    6,    3],\n",
       "       [   6,    3,    2,    0,    2,    2, 1186,    0,    0,    0],\n",
       "       [   2,    2,    7,    0,    8,    1,    0, 1310,    2,    4],\n",
       "       [   4,    3,    3,    5,    2,    5,    6,    2, 1120,    4],\n",
       "       [   2,    0,    0,    3,    6,    5,    0,    3,    4, 1087]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(e)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Support_Vectors = best_model.support_vectors_\n",
    "Support_Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26,\n",
       " 185,\n",
       " 226,\n",
       " 462,\n",
       " 524,\n",
       " 563,\n",
       " 594,\n",
       " 647,\n",
       " 664,\n",
       " 720,\n",
       " 733,\n",
       " 935,\n",
       " 1003,\n",
       " 1062,\n",
       " 1088,\n",
       " 1254,\n",
       " 1285,\n",
       " 1324,\n",
       " 1330,\n",
       " 1555,\n",
       " 1580,\n",
       " 1596,\n",
       " 1640,\n",
       " 1724,\n",
       " 1905,\n",
       " 2081,\n",
       " 2095,\n",
       " 2184,\n",
       " 2191,\n",
       " 2269,\n",
       " 2344,\n",
       " 2358,\n",
       " 2360,\n",
       " 2514,\n",
       " 2714,\n",
       " 2716,\n",
       " 2725,\n",
       " 2821,\n",
       " 2954,\n",
       " 3064,\n",
       " 3073,\n",
       " 3255,\n",
       " 3317,\n",
       " 3465,\n",
       " 3595,\n",
       " 3729,\n",
       " 3787,\n",
       " 3790,\n",
       " 3909,\n",
       " 3983,\n",
       " 4061,\n",
       " 4186,\n",
       " 4233,\n",
       " 4391,\n",
       " 4493,\n",
       " 4561,\n",
       " 4616,\n",
       " 4784,\n",
       " 4860,\n",
       " 4935,\n",
       " 4948,\n",
       " 5119,\n",
       " 5177,\n",
       " 5231,\n",
       " 5282,\n",
       " 5325,\n",
       " 5487,\n",
       " 5539,\n",
       " 5626,\n",
       " 5673,\n",
       " 5703,\n",
       " 5731,\n",
       " 5732,\n",
       " 5765,\n",
       " 5861,\n",
       " 5931,\n",
       " 5943,\n",
       " 6262,\n",
       " 6290,\n",
       " 6377,\n",
       " 6520,\n",
       " 6605,\n",
       " 6691,\n",
       " 6738,\n",
       " 6829,\n",
       " 6845,\n",
       " 6872,\n",
       " 6891,\n",
       " 7012,\n",
       " 7041,\n",
       " 7064,\n",
       " 7071,\n",
       " 7123,\n",
       " 7137,\n",
       " 7186,\n",
       " 7387,\n",
       " 7543,\n",
       " 7632,\n",
       " 7700,\n",
       " 7710,\n",
       " 7770,\n",
       " 7866,\n",
       " 7875,\n",
       " 7911,\n",
       " 7942,\n",
       " 7978,\n",
       " 7990,\n",
       " 8015,\n",
       " 8027,\n",
       " 8199,\n",
       " 8258,\n",
       " 8451,\n",
       " 8508,\n",
       " 8516,\n",
       " 8551,\n",
       " 8589,\n",
       " 8598,\n",
       " 8623,\n",
       " 8643,\n",
       " 8725,\n",
       " 8814,\n",
       " 8971,\n",
       " 9136,\n",
       " 9151,\n",
       " 9399,\n",
       " 9405,\n",
       " 9483,\n",
       " 9488,\n",
       " 9585,\n",
       " 9809,\n",
       " 9881,\n",
       " 9951,\n",
       " 9990,\n",
       " 10026,\n",
       " 10673,\n",
       " 10864,\n",
       " 10937,\n",
       " 10976,\n",
       " 10986,\n",
       " 10988,\n",
       " 11020,\n",
       " 11071,\n",
       " 11073,\n",
       " 11158,\n",
       " 11396,\n",
       " 11397,\n",
       " 11471,\n",
       " 11552,\n",
       " 11679,\n",
       " 11762,\n",
       " 11791,\n",
       " 11885,\n",
       " 11928,\n",
       " 12012,\n",
       " 12019,\n",
       " 12185,\n",
       " 12334,\n",
       " 12348,\n",
       " 12587,\n",
       " 12973,\n",
       " 13056,\n",
       " 13117,\n",
       " 13188,\n",
       " 13203,\n",
       " 13283,\n",
       " 13362,\n",
       " 13407,\n",
       " 13450,\n",
       " 13496,\n",
       " 13589,\n",
       " 13619,\n",
       " 13661,\n",
       " 13688,\n",
       " 13720,\n",
       " 13737,\n",
       " 13974,\n",
       " 14050,\n",
       " 14193,\n",
       " 14220,\n",
       " 14258,\n",
       " 14336,\n",
       " 14370,\n",
       " 14490,\n",
       " 14545,\n",
       " 14572,\n",
       " 14580,\n",
       " 14612,\n",
       " 14620,\n",
       " 14795,\n",
       " 14871,\n",
       " 14875,\n",
       " 14922,\n",
       " 15140,\n",
       " 15333,\n",
       " 15407,\n",
       " 15510,\n",
       " 15564,\n",
       " 15572,\n",
       " 15647,\n",
       " 15732,\n",
       " 15783,\n",
       " 15822,\n",
       " 16063,\n",
       " 16172,\n",
       " 16320,\n",
       " 16408,\n",
       " 16530,\n",
       " 16583,\n",
       " 16588,\n",
       " 16686,\n",
       " 16781,\n",
       " 16841,\n",
       " 16880,\n",
       " 17382,\n",
       " 17397,\n",
       " 17455,\n",
       " 17540,\n",
       " 17580,\n",
       " 17643,\n",
       " 17716,\n",
       " 17759,\n",
       " 17851,\n",
       " 17855,\n",
       " 17925,\n",
       " 18105,\n",
       " 18221,\n",
       " 18265,\n",
       " 18400,\n",
       " 18441,\n",
       " 18479,\n",
       " 18536,\n",
       " 18701,\n",
       " 18707,\n",
       " 18734,\n",
       " 18912,\n",
       " 19025,\n",
       " 19109,\n",
       " 19152,\n",
       " 19438,\n",
       " 19603,\n",
       " 19766,\n",
       " 19776,\n",
       " 19882,\n",
       " 19898,\n",
       " 19916,\n",
       " 19939,\n",
       " 19952,\n",
       " 20010,\n",
       " 20082,\n",
       " 20211,\n",
       " 20226,\n",
       " 20312,\n",
       " 20314,\n",
       " 20488,\n",
       " 20490,\n",
       " 20599,\n",
       " 20626,\n",
       " 20824,\n",
       " 20911,\n",
       " 21114,\n",
       " 21129,\n",
       " 21180,\n",
       " 21368,\n",
       " 21397,\n",
       " 21514,\n",
       " 21601,\n",
       " 21701,\n",
       " 21769,\n",
       " 21805,\n",
       " 21808,\n",
       " 21910,\n",
       " 22005,\n",
       " 22021,\n",
       " 22050,\n",
       " 22124,\n",
       " 22302,\n",
       " 22347,\n",
       " 22568,\n",
       " 22666,\n",
       " 23042,\n",
       " 23218,\n",
       " 23246,\n",
       " 23314,\n",
       " 23419,\n",
       " 23433,\n",
       " 23475,\n",
       " 23486,\n",
       " 23509,\n",
       " 23645,\n",
       " 23661,\n",
       " 23682,\n",
       " 23685,\n",
       " 23716,\n",
       " 23751,\n",
       " 23777,\n",
       " 23778,\n",
       " 23811,\n",
       " 23869,\n",
       " 23939,\n",
       " 23944,\n",
       " 23974,\n",
       " 24036,\n",
       " 24113,\n",
       " 24448,\n",
       " 24532,\n",
       " 24582,\n",
       " 24682,\n",
       " 24739,\n",
       " 24756,\n",
       " 24831,\n",
       " 24953,\n",
       " 25077,\n",
       " 25098,\n",
       " 25142,\n",
       " 25249,\n",
       " 25413,\n",
       " 25464,\n",
       " 25541,\n",
       " 25742,\n",
       " 25813,\n",
       " 25972,\n",
       " 25982,\n",
       " 26010,\n",
       " 26078,\n",
       " 26142,\n",
       " 26230,\n",
       " 26253,\n",
       " 26291,\n",
       " 26294,\n",
       " 26314,\n",
       " 26362,\n",
       " 26372,\n",
       " 26524,\n",
       " 26648,\n",
       " 26747,\n",
       " 27058,\n",
       " 27193,\n",
       " 27313,\n",
       " 27382,\n",
       " 27414,\n",
       " 27525,\n",
       " 27555,\n",
       " 27599,\n",
       " 27639,\n",
       " 27736,\n",
       " 27941,\n",
       " 28173,\n",
       " 28206,\n",
       " 28238,\n",
       " 28288,\n",
       " 28433,\n",
       " 28620,\n",
       " 28621,\n",
       " 28637,\n",
       " 28886,\n",
       " 28951,\n",
       " 29047,\n",
       " 29094,\n",
       " 29187,\n",
       " 29373,\n",
       " 29387,\n",
       " 29443,\n",
       " 29550,\n",
       " 29674,\n",
       " 29678,\n",
       " 29685,\n",
       " 29833,\n",
       " 29892,\n",
       " 30259,\n",
       " 30267,\n",
       " 30296,\n",
       " 30357,\n",
       " 30568,\n",
       " 30620,\n",
       " 30655,\n",
       " 30730,\n",
       " 30782,\n",
       " 30898,\n",
       " 30907,\n",
       " 30953,\n",
       " 31108,\n",
       " 31144,\n",
       " 31206,\n",
       " 31248,\n",
       " 31436,\n",
       " 31459,\n",
       " 31660,\n",
       " 31826,\n",
       " 31896,\n",
       " 31898,\n",
       " 31916,\n",
       " 31983,\n",
       " 32096,\n",
       " 32112,\n",
       " 32161,\n",
       " 32166,\n",
       " 32168,\n",
       " 32178,\n",
       " 32194,\n",
       " 32294,\n",
       " 32463,\n",
       " 32511,\n",
       " 32552,\n",
       " 32675,\n",
       " 32683,\n",
       " 32710,\n",
       " 32835,\n",
       " 32859,\n",
       " 32912,\n",
       " 32972,\n",
       " 33057,\n",
       " 33296,\n",
       " 33408,\n",
       " 33477,\n",
       " 33666,\n",
       " 33679,\n",
       " 33680,\n",
       " 33717,\n",
       " 33923,\n",
       " 33926,\n",
       " 33999,\n",
       " 34011,\n",
       " 34022,\n",
       " 34252,\n",
       " 34293,\n",
       " 34357,\n",
       " 34366,\n",
       " 34386,\n",
       " 34482,\n",
       " 34500,\n",
       " 34559,\n",
       " 34642,\n",
       " 34858,\n",
       " 34963,\n",
       " 35058,\n",
       " 35068,\n",
       " 35176,\n",
       " 35213,\n",
       " 35224,\n",
       " 35270,\n",
       " 35322,\n",
       " 35386,\n",
       " 35403,\n",
       " 35451,\n",
       " 35496,\n",
       " 35584,\n",
       " 35687,\n",
       " 35796,\n",
       " 35874,\n",
       " 35896,\n",
       " 35960,\n",
       " 36003,\n",
       " 36309,\n",
       " 36363,\n",
       " 36444,\n",
       " 36477,\n",
       " 36490,\n",
       " 36513,\n",
       " 36644,\n",
       " 36651,\n",
       " 36761,\n",
       " 36801,\n",
       " 36845,\n",
       " 36851,\n",
       " 37089,\n",
       " 37136,\n",
       " 37160,\n",
       " 37182,\n",
       " 37222,\n",
       " 37253,\n",
       " 37306,\n",
       " 37325,\n",
       " 37338,\n",
       " 37436,\n",
       " 37462,\n",
       " 37536,\n",
       " 37570,\n",
       " 37578,\n",
       " 37585,\n",
       " 37589,\n",
       " 37593,\n",
       " 37743,\n",
       " 37845,\n",
       " 37860,\n",
       " 37914,\n",
       " 37917,\n",
       " 37929,\n",
       " 38038,\n",
       " 38041,\n",
       " 38164,\n",
       " 38253,\n",
       " 38289,\n",
       " 38366,\n",
       " 38673,\n",
       " 38675,\n",
       " 38724,\n",
       " 38805,\n",
       " 38826,\n",
       " 39025,\n",
       " 39053,\n",
       " 39067,\n",
       " 39106,\n",
       " 39152,\n",
       " 39245,\n",
       " 39258,\n",
       " 39281,\n",
       " 39361,\n",
       " 39388,\n",
       " 39530,\n",
       " 39621,\n",
       " 39642,\n",
       " 39666,\n",
       " 39734,\n",
       " 39843,\n",
       " 39894,\n",
       " 39902,\n",
       " 39909,\n",
       " 39959,\n",
       " 39961,\n",
       " 40078,\n",
       " 40091,\n",
       " 40222,\n",
       " 40336,\n",
       " 40402,\n",
       " 40456,\n",
       " 40604,\n",
       " 40682,\n",
       " 40717,\n",
       " 40791,\n",
       " 40872,\n",
       " 41038,\n",
       " 41250,\n",
       " 41290,\n",
       " 41332,\n",
       " 41348,\n",
       " 41397,\n",
       " 41400,\n",
       " 41660,\n",
       " 41825,\n",
       " 41936,\n",
       " 41954,\n",
       " 42076,\n",
       " 42099,\n",
       " 42109,\n",
       " 42122,\n",
       " 42146,\n",
       " 42197,\n",
       " 42237,\n",
       " 42345,\n",
       " 42356,\n",
       " 42452,\n",
       " 42508,\n",
       " 42529,\n",
       " 42554,\n",
       " 42625,\n",
       " 42722,\n",
       " 42756,\n",
       " 42887,\n",
       " 43054,\n",
       " 43102,\n",
       " 43131,\n",
       " 43177,\n",
       " 43316,\n",
       " 43364,\n",
       " 43526,\n",
       " 43594,\n",
       " 43600,\n",
       " 43739,\n",
       " 43832,\n",
       " 43963,\n",
       " 44010,\n",
       " 44027,\n",
       " 44028,\n",
       " 44099,\n",
       " 44168,\n",
       " 44169,\n",
       " 44215,\n",
       " 44221,\n",
       " 44262,\n",
       " 44455,\n",
       " 44472,\n",
       " 44501,\n",
       " 44603,\n",
       " 44611,\n",
       " 44633,\n",
       " 44671,\n",
       " 44909,\n",
       " 44986,\n",
       " 45037,\n",
       " 45107,\n",
       " 45167,\n",
       " 45225,\n",
       " 45399,\n",
       " 45486,\n",
       " 45584,\n",
       " 45607,\n",
       " 45620,\n",
       " 45675,\n",
       " 45707,\n",
       " 45825,\n",
       " 45851,\n",
       " 45864,\n",
       " 45910,\n",
       " 46076,\n",
       " 46231,\n",
       " 46370,\n",
       " 46475,\n",
       " 46623,\n",
       " 46625,\n",
       " 46756,\n",
       " 46894,\n",
       " 47006,\n",
       " 47091,\n",
       " 47126,\n",
       " 47155,\n",
       " 47193,\n",
       " 47332,\n",
       " 47444,\n",
       " 47492,\n",
       " 47634,\n",
       " 47655,\n",
       " 47729,\n",
       " 47731,\n",
       " 47811,\n",
       " 47917,\n",
       " 224,\n",
       " 270,\n",
       " 328,\n",
       " 486,\n",
       " 504,\n",
       " 637,\n",
       " 666,\n",
       " 672,\n",
       " 1001,\n",
       " 1036,\n",
       " 1081,\n",
       " 1269,\n",
       " 1322,\n",
       " 1525,\n",
       " 1647,\n",
       " 1754,\n",
       " 1755,\n",
       " 1870,\n",
       " 1899,\n",
       " 2052,\n",
       " 2054,\n",
       " 2152,\n",
       " 2203,\n",
       " 2285,\n",
       " 2327,\n",
       " 2441,\n",
       " 2984,\n",
       " 3014,\n",
       " 3082,\n",
       " 3158,\n",
       " 3203,\n",
       " 3218,\n",
       " 3245,\n",
       " 3607,\n",
       " 3656,\n",
       " 3698,\n",
       " 3704,\n",
       " 3769,\n",
       " 3783,\n",
       " 3853,\n",
       " 3890,\n",
       " 4028,\n",
       " 4140,\n",
       " 4184,\n",
       " 4189,\n",
       " 4819,\n",
       " 4824,\n",
       " 4913,\n",
       " 4945,\n",
       " 5010,\n",
       " 5028,\n",
       " 5062,\n",
       " 5208,\n",
       " 5234,\n",
       " 5317,\n",
       " 5384,\n",
       " 5457,\n",
       " 5734,\n",
       " 6121,\n",
       " 6206,\n",
       " 6431,\n",
       " 6447,\n",
       " 6486,\n",
       " 6678,\n",
       " 6689,\n",
       " 6705,\n",
       " 6751,\n",
       " 6883,\n",
       " 6914,\n",
       " 6968,\n",
       " 7105,\n",
       " 7268,\n",
       " 7325,\n",
       " 7344,\n",
       " 7414,\n",
       " 7425,\n",
       " 7460,\n",
       " 7461,\n",
       " 7491,\n",
       " 7534,\n",
       " 7610,\n",
       " 7665,\n",
       " 7725,\n",
       " 7780,\n",
       " 7903,\n",
       " 7921,\n",
       " 8140,\n",
       " 8210,\n",
       " 8249,\n",
       " 8309,\n",
       " 8433,\n",
       " 8467,\n",
       " 8802,\n",
       " 8883,\n",
       " 8894,\n",
       " 8921,\n",
       " 9036,\n",
       " 9051,\n",
       " 9165,\n",
       " 9223,\n",
       " 9248,\n",
       " 9355,\n",
       " 9662,\n",
       " 9685,\n",
       " 9753,\n",
       " 10114,\n",
       " 10305,\n",
       " 10484,\n",
       " 10496,\n",
       " 10499,\n",
       " 10928,\n",
       " 11321,\n",
       " 11379,\n",
       " 11574,\n",
       " 11951,\n",
       " 11973,\n",
       " 12073,\n",
       " 12095,\n",
       " 12131,\n",
       " 12156,\n",
       " 12159,\n",
       " 12179,\n",
       " 12219,\n",
       " 12402,\n",
       " 12433,\n",
       " 12621,\n",
       " 12772,\n",
       " 12894,\n",
       " 13006,\n",
       " 13246,\n",
       " 13254,\n",
       " 13405,\n",
       " 13510,\n",
       " 13524,\n",
       " 13695,\n",
       " 13709,\n",
       " 13734,\n",
       " 13786,\n",
       " 13930,\n",
       " 14056,\n",
       " 14239,\n",
       " 14250,\n",
       " 14255,\n",
       " 14315,\n",
       " 14328,\n",
       " 14347,\n",
       " 14421,\n",
       " 14437,\n",
       " 14596,\n",
       " 14933,\n",
       " 15263,\n",
       " 15329,\n",
       " 15432,\n",
       " 15491,\n",
       " 15773,\n",
       " 15933,\n",
       " 16018,\n",
       " 16201,\n",
       " 16444,\n",
       " 16451,\n",
       " 16560,\n",
       " 16597,\n",
       " 16808,\n",
       " 16815,\n",
       " 16825,\n",
       " 16925,\n",
       " 17163,\n",
       " 17170,\n",
       " 17231,\n",
       " 17349,\n",
       " 17470,\n",
       " 17632,\n",
       " 17707,\n",
       " 17740,\n",
       " 17750,\n",
       " 17836,\n",
       " 18180,\n",
       " 18182,\n",
       " 18328,\n",
       " 18368,\n",
       " 18807,\n",
       " 18826,\n",
       " 18844,\n",
       " 18999,\n",
       " 19112,\n",
       " 19200,\n",
       " 19423,\n",
       " 19452,\n",
       " 19491,\n",
       " 19515,\n",
       " 19910,\n",
       " 19921,\n",
       " 19969,\n",
       " 20060,\n",
       " 20452,\n",
       " 20669,\n",
       " 20686,\n",
       " 20754,\n",
       " 20849,\n",
       " 21078,\n",
       " 21097,\n",
       " 21139,\n",
       " 21232,\n",
       " 21289,\n",
       " 21529,\n",
       " 21781,\n",
       " 21817,\n",
       " 21984,\n",
       " 21997,\n",
       " 22387,\n",
       " 22526,\n",
       " 22799,\n",
       " 22862,\n",
       " 22910,\n",
       " 23018,\n",
       " 23079,\n",
       " 23106,\n",
       " 23172,\n",
       " 23251,\n",
       " 23715,\n",
       " 23779,\n",
       " 24421,\n",
       " 24460,\n",
       " 24529,\n",
       " 24642,\n",
       " 24705,\n",
       " 24713,\n",
       " 24719,\n",
       " 24830,\n",
       " 24852,\n",
       " 25069,\n",
       " 25346,\n",
       " 25381,\n",
       " 25537,\n",
       " 25555,\n",
       " 25569,\n",
       " 25718,\n",
       " 25738,\n",
       " 25835,\n",
       " 26097,\n",
       " 26231,\n",
       " 26375,\n",
       " 26451,\n",
       " 26745,\n",
       " 26754,\n",
       " 26867,\n",
       " 27029,\n",
       " 27055,\n",
       " 27164,\n",
       " 27372,\n",
       " 27544,\n",
       " 27616,\n",
       " 27717,\n",
       " 27725,\n",
       " 27734,\n",
       " 27791,\n",
       " 27797,\n",
       " 27868,\n",
       " 27898,\n",
       " 27924,\n",
       " 27933,\n",
       " 28008,\n",
       " 28330,\n",
       " 28665,\n",
       " 28682,\n",
       " 28731,\n",
       " 28961,\n",
       " 28974,\n",
       " 29069,\n",
       " 29368,\n",
       " 29388,\n",
       " 29506,\n",
       " 29551,\n",
       " 29653,\n",
       " 29874,\n",
       " 30047,\n",
       " 30537,\n",
       " 30606,\n",
       " 30660,\n",
       " 30809,\n",
       " 30836,\n",
       " 30908,\n",
       " 30978,\n",
       " 31083,\n",
       " 31128,\n",
       " 31187,\n",
       " 31218,\n",
       " 31323,\n",
       " 31342,\n",
       " 31501,\n",
       " 31680,\n",
       " 31731,\n",
       " 31757,\n",
       " 31929,\n",
       " 31940,\n",
       " 32132,\n",
       " 32322,\n",
       " 32333,\n",
       " 32362,\n",
       " 32364,\n",
       " 32474,\n",
       " 32521,\n",
       " 32553,\n",
       " 33133,\n",
       " 33207,\n",
       " 33367,\n",
       " 33388,\n",
       " 33455,\n",
       " 33652,\n",
       " 33748,\n",
       " 33779,\n",
       " 33965,\n",
       " 33988,\n",
       " 34272,\n",
       " 34456,\n",
       " 34774,\n",
       " 34976,\n",
       " 35106,\n",
       " 35227,\n",
       " 35275,\n",
       " 35511,\n",
       " 35558,\n",
       " 35577,\n",
       " 35607,\n",
       " 35621,\n",
       " 35634,\n",
       " 35637,\n",
       " 35694,\n",
       " 35749,\n",
       " 35818,\n",
       " 35882,\n",
       " 35924,\n",
       " 36016,\n",
       " 36141,\n",
       " 36172,\n",
       " 36320,\n",
       " 36565,\n",
       " 36633,\n",
       " 37178,\n",
       " 37184,\n",
       " 37274,\n",
       " 37455,\n",
       " 37627,\n",
       " 37884,\n",
       " 37915,\n",
       " 38042,\n",
       " 38074,\n",
       " 38181,\n",
       " 38213,\n",
       " 38294,\n",
       " 38375,\n",
       " 38626,\n",
       " 38727,\n",
       " 38861,\n",
       " 39052,\n",
       " 39272,\n",
       " 39505,\n",
       " 39678,\n",
       " 39729,\n",
       " 39745,\n",
       " 39805,\n",
       " 39885,\n",
       " 40033,\n",
       " 40180,\n",
       " 40218,\n",
       " 40240,\n",
       " 40337,\n",
       " 40524,\n",
       " 40605,\n",
       " 40634,\n",
       " 40828,\n",
       " 40877,\n",
       " 41040,\n",
       " 41114,\n",
       " 41209,\n",
       " ...]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indices of support vectors\n",
    "list_svI = list(best_model.support_)\n",
    "list_svI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 625,  450, 1060, 1095,  980, 1139,  743,  859, 1309, 1258],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of support vectors for each class\n",
    "best_model.n_support_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_training_Set = train_data.iloc[train_data.index.isin(list_svI)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47967</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47979</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47985</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47993</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47999</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9518 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "3          1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4          9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "17         8    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "23         1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "25         2    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
       "47967      8    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "47979      3    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "47985      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "47993      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "47999      2    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "       28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "3          0      0      0      0      0      0      0      0  \n",
       "4          0      0      0      0      0      0      0      0  \n",
       "17         0      0      0      0      0      0      0      0  \n",
       "23         0      0      0      0      0      0      0      0  \n",
       "25         0      0      0      0      0      0      0      0  \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "47967      0      0      0      0      0      0      0      0  \n",
       "47979      0      0      0      0      0      0      0      0  \n",
       "47985      0      0      0      0      0      0      0      0  \n",
       "47993      0      0      0      0      0      0      0      0  \n",
       "47999      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[9518 rows x 785 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_training_Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new = new_training_Set['label'] \n",
    "x_new = new_training_Set.drop(columns = 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = x_new/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10, gamma=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10, gamma=0.01)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10, gamma=0.01)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newtrain_model = SVC(C= 10,kernel='rbf', gamma= 0.01)\n",
    "newtrain_model.fit(x_new, y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_new = newtrain_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Train Accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9704583333333333"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, y_pred_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Test Accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_newtest = newtrain_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9725833333333334"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_newtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+------------+\n",
      "| Model                                      |   Accuracy |\n",
      "+============================================+============+\n",
      "| Linear SVM                                 |   0.934583 |\n",
      "+--------------------------------------------+------------+\n",
      "| RBF Non-Linear SVM                         |   0.97825  |\n",
      "+--------------------------------------------+------------+\n",
      "| Polynomial Non-Linear SVM                  |   0.976833 |\n",
      "+--------------------------------------------+------------+\n",
      "| Best Model(RBF) with C=10 & gamma=0.01     |   0.982417 |\n",
      "+--------------------------------------------+------------+\n",
      "| Support Vector Extraction Model---Training |   0.970458 |\n",
      "+--------------------------------------------+------------+\n",
      "| Support Vector Extraction Model---Test     |   0.972583 |\n",
      "+--------------------------------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "mydata = [\n",
    "    [\"Linear SVM\", \"0.9345833333333333\"],\n",
    "    [\"RBF Non-Linear SVM\", \"0.97825\"],\n",
    "    [\"Polynomial Non-Linear SVM\", \"0.976833333333333\"],\n",
    "    [\"Best Model(RBF) with C=10 & gamma=0.01\", \"0.982416666667\"],\n",
    "    [\"Support Vector Extraction Model---Training\",\"0.9704583333333333\"],\n",
    "    [\"Support Vector Extraction Model---Test\",\"0.9725833333333334\"]\n",
    "]\n",
    "head = [\"Model\", \"Accuracy\"]\n",
    "print(tabulate(mydata, headers=head, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "<br> (1) All the models showed good accuracies.</br>\n",
    "<br> (2) After doing cross validation we found the best accuracy of the model that is at `C=10` & `gamma = 0.01` we got `98% accuracy`. </br>\n",
    "<br> (3) After Support vector extraction the accuracy somewhat remained the same.</br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
